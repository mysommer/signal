const e=[{id:"post-1",title:'The End of "User" Experience',excerpt:"Why the era of direct manipulation is shifting to intent-based agency.",date:"OCT 12, 2025",readTime:"4 MIN",content:`We are witnessing the death of the "User" as we know it.

    For decades, Human-Computer Interaction (HCI) has been predicated on the idea of direct manipulation: the user clicks, the system responds. The user drags, the system moves. This model assumes the user is the sole initiator of action.

    Agentic AI flips this paradigm. We are moving towards "Intent-Based Interaction". The user defines a goal—"Organize a meeting with these three people"—and the system engages in a complex, autonomous workflow to achieve it.

    The UI of the future is not a dashboard of buttons; it is a collaborative space where humans and agents negotiate outcomes. Usefulness will no longer be measured by how many clicks it takes to do a task, but by how much "Cognitive Drift" the system removes from your day.`},{id:"post-2",title:"Digital Twins & The Right to Reality",excerpt:"As we upload our identity, who owns the simulation?",date:"NOV 05, 2025",readTime:"6 MIN",content:`When your Digital Twin can predict your health outcomes better than your doctor, and your consumer behavior better than you can, it becomes more "real" than your physical self in the eyes of the market.

    The "Right to Reality" is a proposed human right that ensures:
    1. You own the predictive data generated by your Twin.
    2. You have the right to "disconnect" your Twin from commercial simulations.
    3. You have the right to know when you are interacting with another human's Twin versus the human themselves.

    Without these rights, we risk becoming mere shadow puppets of our digital proxies.`},{id:"post-3",title:"Beyond the Black Box",excerpt:"Transparency as the new aesthetic in AI systems.",date:"DEC 20, 2025",readTime:"3 MIN",content:`Opacity is no longer a luxury of "magic". In high-stakes environments—healthcare, justice, finance—the "Black Box" nature of Deep Learning is a liability.

    We argue that "Explainability" is not just a technical requirement; it is an aesthetic choice. A system that can visualize its reasoning, that can show the "why" behind the "what", builds a profound trust.

    At BY SOMMER, we design "Glass Box" interfaces. We use visual metaphors—nodes, connecting lines, weight visualizations—to make the invisible logic of the machine beautiful and understandable.`}],t=[{id:"ep-1",title:"Ep. 01: The Synthetic Soul",duration:"46:12",description:"Exploring the philosophical implications of sentient Digital Twins.",guest:"Dr. A. Vance"},{id:"ep-2",title:"Ep. 02: Governing the Swarm",duration:"38:45",description:"How to regulate autonomous agent swarms without stifling innovation.",guest:"L. Chen"},{id:"ep-3",title:"Ep. 03: Silence in the Algorithm",duration:"52:00",description:"The role of silence and negative space in AI communication.",guest:"M. Sommer"}];export{e as B,t as P};
